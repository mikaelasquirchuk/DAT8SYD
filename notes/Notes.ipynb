{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 1 Lesson 1: Welcome + course overview\n",
    "1 - 23 May 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Course overview\n",
    "* First, get a basic level of all the different areas of Data Science - theory, programming, statistics, visualisation, communication, subject matter expertise.\n",
    "* Then get to go into further detail in more advanced areas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional readings\n",
    "* Python for Data Analysis:  http://shop.oreilly.com/product/0636920023784.do\n",
    "* Command Line Crash Course: http://cli.learncodethehardway.org/book/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 1 Lesson 2: Git + Github, Numpy + Pandas\n",
    "2 - 25 May 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Git\n",
    "* Version control system that allows you to track files and file changes in a repository (“repo”)\n",
    "* Primarily used by software developers\n",
    "* Most widely used version control system\n",
    "* Alternatives: Mercurial, Subversion, CVS\n",
    "* Runs from the command line (usually)\n",
    "* Can be used alone or in a team\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Github\n",
    "* Allows you to put your Git repos online\n",
    "* Alternative: Bitbucket\n",
    "* Benefits of GitHub:\n",
    " * Backup of files\n",
    " * Visual interface for navigating repos\n",
    " * Makes repo collaboration easy\n",
    "* Git does not require GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=git_chart.png width=500 align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy\n",
    "\n",
    "* Numpy can be used to perform general maths functions, and also create arrays of data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.array( [20,30,40,50] )\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = np.arange(4)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = a-b\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = b*2\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = np.random.randint(1,10,(2,3,4))\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas\n",
    "* Pandas is all about that reading. You can read files using pandas, including CSV files, URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.read_table('../data/u.user', header=None)\n",
    "user_cols = ['user_id', 'age', 'gender', 'occupation', 'zip_code']\n",
    "users = pd.read_table('../data/u.user', sep='|', header=None, names=user_cols, index_col='user_id', dtype={'zip_code':str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users                   # print the first 30 and last 30 rows\n",
    "type(users)             # DataFrame\n",
    "users.head()            # print the first 5 rows\n",
    "users.head(10)          # print the first 10 rows\n",
    "users.tail()            # print the last 5 rows\n",
    "users.index             # \"the index\" (aka \"the labels\")\n",
    "users.columns           # column names (which is \"an index\")\n",
    "users.dtypes            # data types of each column\n",
    "users.shape             # number of rows and columns\n",
    "users.values            # underlying numpy array\n",
    "users.info()            # concise summary (including memory usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#users['gender']         # select one column\n",
    "#type(users['gender'])   # Series\n",
    "#users[['gender']]\n",
    "#type(users[['gender']])   # DataFrame\n",
    "#users.gender            # select one column using the DataFrame attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#users.describe()                    # describe all numeric columns\n",
    "#users.describe(include=['object'])  # describe all object columns (can include multiple types)\n",
    "#users.describe(include='all')       # describe all columns\n",
    "#users.gender.describe()             # describe a single column\n",
    "users.age.mean()                    # only calculate the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#users.occupation.value_counts()     # most useful for categorical variables\n",
    "users.age.value_counts()        # can also be used with numeric variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#young_bool = users.age < 20         # create a Series of booleans...\n",
    "#users[young_bool]                   # ...and use that Series to filter rows\n",
    "#users[users.age < 20]               # or, combine into a single step\n",
    "#users[users.age < 20].occupation    # select one column from the filtered results\n",
    "users[users.age < 20].occupation.value_counts()     # value_counts of resulting Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# logical filtering with multiple conditions\n",
    "#users[(users.age < 20) & (users.gender=='M')]       # ampersand for AND condition\n",
    "#users[(users.age < 20) | (users.age > 60)]          # pipe for OR condition\n",
    "users[users.occupation.isin(['doctor', 'lawyer'])]  # alternative to multiple OR conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users.age.sort_values()                   # sort a column\n",
    "users.sort_values(by='age')                   # sort a DataFrame by a single column\n",
    "users.sort_values(by='age', ascending=False)  # use descending order instead\n",
    "users.sort_values(by=['occupation', 'age'])   # sort by multiple columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users.age.value_counts()              # excludes missing values\n",
    "users.age.value_counts(dropna=False)  # includes missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users.age.isnull()           # True if missing, False if not missing\n",
    "#users.age.isnull().sum()     # count the missing values\n",
    "#users.age.notnull()          # True if not missing, False if missing\n",
    "#users[users.age.notnull()]  # only show rows where continent is not missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use 'tilde' ~ to negate the boolean values\n",
    "~users.age.isnull()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users.isnull()             # DataFrame of booleans\n",
    "users.isnull().sum()       # count the missing values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users.age.fillna(value='NA')                 # fill in missing values with 'NA'\n",
    "users.age.fillna(value='NA', inplace=True)   # modifies 'drinks' in-place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users.sum(axis=0)      # sums \"down\" the 0 axis (rows)\n",
    "users.sum()            # axis=0 is the default\n",
    "users.sum(axis=1)      # sums \"across\" the 1 axis (columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional readings\n",
    "[Basic Git commands list](\"https://confluence.atlassian.com/bitbucketserver/basic-git-commands-776639767.html\")\n",
    "\n",
    "[Good resourses](\"https://help.github.com/articles/git-and-github-learning-resources/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 2 Lesson 1: Visualisation\n",
    "3 - 30 May 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import matplotlib.pyplot as plt\n",
    "#!pip install seaborn\n",
    "import seaborn as sns\n",
    "#!pip install seaborn\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go \n",
    "#!pip install folium\n",
    "import folium\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "plotly.tools.set_credentials_file(username='Msquirchuk', api_key='kTj4gydNrsbGuMDjMcNn')\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is data visualisation?\n",
    "* Data visualisation is the representation of data in a graphical way to more easily or clearly convey the patterns in data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why do we visualise data?\n",
    "* Visualisation helps data analysts:\n",
    " * understand the data and what patterns exist (exploratory);\n",
    " * explain the data to non-data-ists (reporting) or in a simple way.\n",
    "* The greatest value of a picture is when it forces us to notice what we never expected to see. - John W Tukey, Exploratory Data Analysis, 1977."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can we visualise data?\n",
    "* There are many data visualisation tools: the easier ones to use can do less stuff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pythonvislandscape.png\" width=450 align=left>\n",
    "<img src=\"chart-suggestions.png\" width=450 align=right>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we visualise data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bar charts\n",
    "* Shows numeric summaries across different categories (either horizontally or vertically)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = [3, 10, 7, 5, 3, 4.5, 6, 8.1]\n",
    "N = len(y)\n",
    "x = range(N)\n",
    "plt.bar(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zoodata = [go.Bar(\n",
    " x=['giraffes', 'orangutans', 'monkeys'],\n",
    " y=[20, 14, 23]\n",
    " )]\n",
    "\n",
    "py.iplot(zoodata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/plotly/datasets/master/school_earnings.csv\")\n",
    "\n",
    "trace_women = Bar(x=df.School,\n",
    "                  y=df.Women,\n",
    "                  name='Women',\n",
    "                  marker=dict(color='#ffcdd2'))\n",
    "\n",
    "trace_men = Bar(x=df.School,\n",
    "                y=df.Men,\n",
    "                name='Men',\n",
    "                marker=dict(color='#A2D5F2'))\n",
    "\n",
    "trace_gap = Bar(x=df.School,\n",
    "                y=df.gap,\n",
    "                name='Gap',\n",
    "                marker=dict(color='#59606D'))\n",
    "\n",
    "data = [trace_women, trace_men, trace_gap]\n",
    "layout = Layout(title=\"Average Earnings for Graduates\",\n",
    "                xaxis=dict(title='School'),\n",
    "                yaxis=dict(title='Salary (in thousands)'))\n",
    "\n",
    "fig = Figure(data=data, layout=layout)\n",
    "\n",
    "py.iplot(fig, filename='styled_bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histograms\n",
    "* Shows the distribution of data over a continuous interval\n",
    "* Allows us to see the shape of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_data=urllib.request.urlopen(\"http://goo.gl/HppjFh\")\n",
    "dataset = pd.read_csv(raw_data, delimiter=\",\", names=('sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'))\n",
    "dataset[['sepal_width']].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset.loc[dataset['species'] == 'Iris-setosa','sepal_length'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.random.randn(500)\n",
    "data = [go.Histogram(x=x)]\n",
    "py.iplot(data, filename='basic histogram') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatterplots\n",
    "* Shows values between two variables, one on each axis.\n",
    "* Used to see a relationship between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(dataset['sepal_length'],dataset['sepal_width'],100,'rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x='sepal_width', y=\"sepal_length\", hue=\"species\", data=dataset, fit_reg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"sepal_width\", y=\"sepal_length\", data=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(dataset, hue='species');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 1000\n",
    "random_x = np.random.randn(N)\n",
    "random_y = np.random.randn(N)\n",
    "trace = go.Scatter(\n",
    " x = random_x,\n",
    " y = random_y,\n",
    " mode = 'markers'\n",
    ")\n",
    "data = [trace]\n",
    "py.iplot(data, filename='basic-scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Box and whisker plots\n",
    "* Displays numerical distribution summaries by groups through quartiles\n",
    "* Can compare different distributions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spread = np.random.rand(50) * 100\n",
    "center = np.ones(25) * 50\n",
    "flier_high = np.random.rand(10) * 100 + 100\n",
    "flier_low = np.random.rand(10) * -100\n",
    "data = np.concatenate((spread, center, flier_high, flier_low), 0)\n",
    "\n",
    "plt.boxplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spread = np.random.rand(50) * 100\n",
    "center = np.ones(25) * 40\n",
    "flier_high = np.random.rand(10) * 100 + 100\n",
    "flier_low = np.random.rand(10) * -100\n",
    "d2 = np.concatenate((spread, center, flier_high, flier_low), 0)\n",
    "data.shape = (-1, 1)\n",
    "d2.shape = (-1, 1)\n",
    "# data = concatenate( (data, d2), 1 )\n",
    "# Making a 2-D array only works if all the columns are the\n",
    "# same length.  If they are not, then use a list instead.\n",
    "# This is actually more efficient because boxplot converts\n",
    "# a 2-D array into a list of vectors internally anyway.\n",
    "data = [data, d2, d2[::2, 0]]\n",
    "# multiple box plots on one figure\n",
    "plt.figure()\n",
    "plt.boxplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y0 = np.random.randn(50)-1\n",
    "y1 = np.random.randn(50)+1\n",
    "trace0 = go.Box(\n",
    " y=y0\n",
    ")\n",
    "trace1 = go.Box(\n",
    " y=y1\n",
    ")\n",
    "data = [trace0, trace1]\n",
    "py.iplot(data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Density plots\n",
    "* Similar to a histogram but smooths out the distribution with a continuous line\n",
    "* Not affected by bin choices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "data = [1.5]*7 + [2.5]*2 + [3.5]*8 + [4.5]*3 + [5.5]*1 + [6.5]*8\n",
    "\n",
    "density = gaussian_kde(data)\n",
    "xs = np.linspace(0,8,200)\n",
    "density.covariance_factor = lambda : .25\n",
    "density._compute_covariance()\n",
    "plt.plot(xs,density(xs))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heat maps\n",
    "* Colour coding applied to tabular data.\n",
    "* Provides a generalised view of the data by each cell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.random.randn(8873)\n",
    "y = np.random.randn(8873)\n",
    "\n",
    "heatmap, xedges, yedges = np.histogram2d(x, y, bins=50)\n",
    "extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "\n",
    "plt.clf()\n",
    "plt.imshow(heatmap.T, extent=extent, origin='lower')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trace = go.Heatmap(z=[[1, 20, 30],\n",
    " [20, 1, 60],\n",
    " [30, 60, 1]])\n",
    "data=[trace]\n",
    "py.iplot(data, filename='basic-heatmap') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.random.randn(2000)\n",
    "y = np.random.randn(2000)\n",
    "plotly.offline.iplot([Histogram2dContour(x=x, y=y, contours=Contours(coloring='heatmap')),\n",
    "       Scatter(x=x, y=y, mode='markers', marker=Marker(color='white', size=3, opacity=0.3))], show_link=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Line graphs\n",
    "* Used to display a numeric value over a continuous value or time\n",
    "* Used to observe trends and changes over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = range(3)\n",
    "x = [3,4,5]\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 500\n",
    "random_x = np.linspace(0, 1, N)\n",
    "random_y = np.random.randn(N)\n",
    "trace = go.Scatter(\n",
    " x = random_x,\n",
    " y = random_y\n",
    ")\n",
    "data = [trace]\n",
    "py.iplot(data, filename='basic-line') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parallel coordinates\n",
    "* Plot multiple numeric variables across each observation\n",
    "* Each axis is scaled and each line through the graph is an observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    go.Parcoords(\n",
    "        line = dict(color = 'blue'),\n",
    "        dimensions = list([\n",
    "            dict(range = [1,5],\n",
    "                 constraintrange = [1,2],\n",
    "                 label = 'A', values = [1,4]),\n",
    "            dict(range = [1.5,5],\n",
    "                 tickvals = [1.5,3,4.5],\n",
    "                 label = 'B', values = [3,1.5]),\n",
    "            dict(range = [1,5],\n",
    "                 tickvals = [1,2,4,5],\n",
    "                 label = 'C', values = [2,4],\n",
    "                 ticktext = ['text 1', 'text 2', 'text 3', 'text 4']),\n",
    "            dict(range = [1,5],\n",
    "                 label = 'D', values = [4,2])\n",
    "        ])\n",
    "    )\n",
    "]\n",
    "\n",
    "py.iplot(data, filename = 'parcoord-dimensions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import parallel_coordinates\n",
    "parallel_coordinates (dataset, 'species')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maps\n",
    "* Allows us to plot points geographically\n",
    "* We can overlay information on a map, usually loaded as a collection of ‘tiles’. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map_object = folium.Map(location=[-33.8, 151.2], zoom_start=2,\n",
    "tiles=\"Stamen toner\")\n",
    "marker = folium.features.Marker([-33.869824, 151.206423],popup=\"General Assembly!\")\n",
    "map_object.add_child(marker) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_airports = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/2011_february_us_airport_traffic.csv')\n",
    "df_airports.head()\n",
    "\n",
    "df_flight_paths = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/2011_february_aa_flight_paths.csv')\n",
    "df_flight_paths.head()\n",
    "\n",
    "airports = [ dict(\n",
    "        type = 'scattergeo',\n",
    "        locationmode = 'USA-states',\n",
    "        lon = df_airports['long'],\n",
    "        lat = df_airports['lat'],\n",
    "        hoverinfo = 'text',\n",
    "        text = df_airports['airport'],\n",
    "        mode = 'markers',\n",
    "        marker = dict(\n",
    "            size=2,\n",
    "            color='rgb(255, 0, 0)',\n",
    "            line = dict(\n",
    "                width=3,\n",
    "                color='rgba(68, 68, 68, 0)'\n",
    "            )\n",
    "        ))]\n",
    "\n",
    "flight_paths = []\n",
    "for i in range( len( df_flight_paths ) ):\n",
    "    flight_paths.append(\n",
    "        dict(\n",
    "            type = 'scattergeo',\n",
    "            locationmode = 'USA-states',\n",
    "            lon = [ df_flight_paths['start_lon'][i], df_flight_paths['end_lon'][i] ],\n",
    "            lat = [ df_flight_paths['start_lat'][i], df_flight_paths['end_lat'][i] ],\n",
    "            mode = 'lines',\n",
    "            line = dict(\n",
    "                width = 1,\n",
    "                color = 'red',\n",
    "            ),\n",
    "            opacity = float(df_flight_paths['cnt'][i])/float(df_flight_paths['cnt'].max()),\n",
    "        )\n",
    "    )\n",
    "\n",
    "layout = dict(\n",
    "        title = 'Feb. 2011 American Airline flight paths<br>(Hover for airport names)',\n",
    "        showlegend = False,\n",
    "        height = 800,\n",
    "        geo = dict(\n",
    "            scope='north america',\n",
    "            projection=dict( type='azimuthal equal area' ),\n",
    "            showland = True,\n",
    "            landcolor = 'rgb(243, 243, 243)',\n",
    "            countrycolor = 'rgb(204, 204, 204)',\n",
    "        ),\n",
    "    )\n",
    "\n",
    "fig = dict( data=flight_paths + airports, layout=layout )\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charts to avoid\n",
    "* Stacked area maps\n",
    "* Word clouds\n",
    "* Pie charts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional readings\n",
    "* Edward Tuſte, The Visual Display of Quantitative Information\n",
    "* Leland Wilkinson, The Grammar of Graphics\n",
    "* Scott Murray, Interactive Data Visualisation for the Web (free online)\n",
    "* flowingdata.com\n",
    "* New York Times (Upshot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 2 Lesson 2: Linear Regression\n",
    "4 - 1 June 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised vs unsupervised learning\n",
    "* Supervised learning is where there is a target output - we want something to come out of our model.\n",
    " * Regression: If the target variable is numeric then we have a regression problem.\n",
    " * cf. Classification: If the target variable is a category (for example trying to predict a type of flower) the we have a classification problem - we are trying to classify what group that y belongs to.\n",
    " * Features: Data values that provide information to help guess the target, aka predictor or independent variables.\n",
    "* Unsupervised learning is where there is no output, but we want to observe the model of the data, e.g. for exploration. We want to find some underlying structure or patterns in the data but in this case we don’t have any labeled data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression \n",
    "* We want to model a linear relationship (think straight line) between our target variable y and our input variable x:\n",
    "y=Xβ+ϵ, where:\n",
    " * y = target variable\n",
    " * X = input variable\n",
    " * β = coefficients\n",
    " * ϵ = error term \n",
    "* It is the explanation of a continuous variable given a series of independent variables.\n",
    "* The simplest version is just a line of best fit: y = mx + b... It explains the relationship between x and y using the starting point b and the power in explanation m.\n",
    "* Linear regression is a simple approach to supervised learning. It assumes that the dependence of Y on X1, X2 ,… Xp is linear. True regression functions are never linear.\n",
    "* Linear relationship in the parameters, β, we can transform the actual values of the inputs if we want.\n",
    "* Variance of the error term, ϵ, is constant. This means there is no systematic pattern in the values of X and the variance of ϵ. The mean of ϵ = 0. ϵ has a normal distribution. If it does not, it could introduce bias. \n",
    "* There will be no perfect (or near perfect) co-linearity between any of the input variables. Otherwise the fitting procedure will break. \n",
    "\n",
    "\n",
    "#### How it works\n",
    "_Ordinary Least Squares_\n",
    "<img src=\"linear-regression-rss.png\" align=right width=300>\n",
    "* Creating a linear regression model is really about minimising the _Residual Sum of Squares_ or RSE. This is the Sum of the squared difference between our observed value and the value from the model. That is: <img src=\"RSS-equation.png\" width=400>\n",
    "* Wording the function as: <img src=\"linear-equation.png\">\n",
    "* Wording RSS as a function of e (error): <img src=\"rssaserror.png\">\n",
    "* Error is just the difference between yi and y as it is observed. So, expanding: <img src=\"rssaserror2.png\">\n",
    "* Resolving this equation, it means:\n",
    "<img src=\"OLS.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R-Squared\n",
    "* R-squared is the central metric introduced for linear regression. The closer to 1 the R-squared, the better the fit. \n",
    "* R-squared measures explain variance, but it doesn't tell the magnitude or scale of error.\n",
    "\n",
    "<img src=\"R2-equations.png\" width=500 align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple linear regression\n",
    "* Multi-dimensions allows for complex models even with linear components.\n",
    "\n",
    "<img src=\"multiple-linear-regression2.png\" align=right width=200 >\n",
    "\n",
    "* The ideal scenario is when the predictors are uncorrelated:\n",
    " * Interpretations can be made such as “a unit change in Xj is associated with a βj change in Y , while all the other variables stay fixed”.\n",
    " * Correlations amongst predictors cause problems when Xj changes, everything else changes.\n",
    "\n",
    " <img src=\"multiple-linear-regression.png\" align=left width=400>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make sure you visualise your data and check the actual model fit !!! \n",
    "See [Anscombe's Quartet](https://en.wikipedia.org/wiki/Anscombe%27s_quartet) for why!\n",
    "<img src=\"anscombes-quartet.png\" width=400 align=right>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "house_data = pd.read_csv(\"../data/chicagohouseprices2.csv\", index_col=0)\n",
    "house_data.head(1)\n",
    "#replace missing data\n",
    "house_data.fillna(value='NA', inplace=True) \n",
    "#look at the correlations between the data\n",
    "pd.scatter_matrix(house_data, figsize=(15,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create the linear model\n",
    "lm1 = smf.ols(formula='Price ~ Bath + HouseSizeSqft', data=house_data).fit()\n",
    "#print the coefficients\n",
    "lm1.params\n",
    "#print the regression results\n",
    "lm1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm2 = smf.ols(formula='Price ~ Bath + CrimeIndex + MinutesToLoop + MilesToLake + Age + LotSizeSqft + HouseSizeSqft + SchoolIndex + EstimatedPrice', data=house_data).fit()\n",
    "lm2.params\n",
    "lm2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 3 Lesson 1: Logistic Regression\n",
    "5 - 6 June 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression vs Classification\n",
    "* If the y variable is numeric then we have a regression problem - we are trying to predict a continuous number\n",
    "* If the y variable is a category (for example trying to predict a type of flower) the we have a classification problem - we are trying to classify what group that y belongs to.\n",
    "* We want to build a classifier that correctly identifies which class our target variable y belongs to given our input variable x. \n",
    "* Why not use the linear regression model? y=Xβ+ϵ\n",
    " * If we only have a binary response variable (0 or 1) it might make sense… BUT we can have our estimated value of y > 1 or y < 0 … which doesn’t make sense.\n",
    " * What of the case where we have more than one class? Linear regression cannot easily handle these cases.\n",
    " * We want a classification method that can handle these cases and give us results we can easily interpret. \n",
    "\n",
    "<img src=\"logit-function.png\" width=400 align=right>\n",
    "### p(1|x) = β0+β1\n",
    "* This is a good starting point but we still have the problem of p(Y) being outside the 0,1 range.\n",
    "* We need to model p(Y=1|X) using a function that gives outputs between 0 and 1. Basically we want something that looks like the following:\n",
    "<img src=\"logistic-regression.png\" width=300 align=right>\n",
    "\n",
    "\n",
    "\n",
    "* We can see that it this function is linear in X\n",
    " * p | (p - 1) is called the ‘odds’ and can be any value from 0 to ∞\n",
    " * log ( p | (p - 1) ) is called the ‘log-odds’ or ‘logit’"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Score\n",
    "* This is simply the fraction of correct predictions from the model. So it is the number of correct predictions divided by the number of observations in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"confusion-matrix.png\" align=right>\n",
    "### Confusion Matrix\n",
    "* A confusion matrix shows us what the predicted class was against what the actual class was. \n",
    "* The true class makes up the rows or the vertical axes and the predicted class makes up the columns or the horizontal axis.\n",
    "* Any entries in the diagonal of the matrix are those that are correctly classified. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"roc-curve.png\" align=right>\n",
    "### Receiver Operating Characteristic\n",
    "\n",
    "* The Receiver Operating Characteristic or ROC curve shows the performance of a binary classifier system as its discrimination threshold is varied. \n",
    "* It is created by plotting the fraction of true positives out of the positives (TPR = true positive rate) vs. the fraction of false positives out of the negatives (FPR = false positive rate), at various threshold settings.\n",
    "* By computing the Area Under the Curve of the ROC curve we get a single number summary of accuracy.\n",
    "* The closer that number is to 1 the more accurate our model is. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional readings\n",
    "* Logistic Regression applied to loan applications https://github.com/nborwankar/LearnDataScience\n",
    "* Odds Ratio in Logistic Regression http://www.ats.ucla.edu/stat/mult_pkg/faq/general/odds_ratio.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 3 Lesson 2: Model Evaluation\n",
    "6 - 8 June 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 4 Lesson 1: Regularisation\n",
    "7 - 13 June 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 4 Lesson 2: Clustering\n",
    "8 - 15 June 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 5 Lesson 1: Recommendation Engines\n",
    "9 - 20 June 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 5 Lesson 2:\n",
    "10 - 22 June 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 6 Lesson 1:\n",
    "11 - 27 June 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 6 Lesson 2:\n",
    "12 - 29 June 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 7 Lesson 1:\n",
    "13 - 4 July 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 7 Lesson 2:\n",
    "14 - 6 July 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 8 Lesson 1:\n",
    "15 - 11 July 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 8 Lesson 2:\n",
    "16 - 13 July 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 9 Lesson 1:\n",
    "17 - 18 July 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 9 Lesson 2:\n",
    "18 - 20 July 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 10 Lesson 1:\n",
    "19 - 25 July 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 10 Lesson 2:\n",
    "20 - 27 July 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
