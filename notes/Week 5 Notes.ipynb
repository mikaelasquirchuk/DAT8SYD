{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5 Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 5 Lesson 1\n",
    "## Recommendation Engines\n",
    "9 - 20 June 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recommendation engines aims to match users to things (movies, songs, items, events, etc) they might enjoy but have not yet tried. The rating is produced by analysing other user/item ratings (and sometimes item characteristics) to provide personalised recommendations to users.\n",
    "- There are two general approaches to the design:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content-based filtering\n",
    "- In content-based filtering, items are mapped into a feature space, and recommendations depend on item characteristics.\n",
    "- Content-based filtering begins by mapping each item into a feature space. Both users and items are represented by vectors in this space. \n",
    "- Item vectors measure the degree to which the item is described by each feature, and user vectors measure a user’s preferences for each feature.\n",
    "- Ratings are generated by taking dot products of user & item vectors.\n",
    "- Content-based filtering has some difficulties: \n",
    " - Must map items into a feature space (manual work)\n",
    " -  Recommendations are limited in scope (items must be similar to each other)\n",
    " - Hard to create cross-content recommendations (eg books/music films...this would require comparing elements from different feature spaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/collaborative_filtering.png\" width=400 align=right>\n",
    "### Collaborative filtering\n",
    "- In contrast, the only data under consideration in collaborative filtering are user-item ratings, and recommendations depend on user preferences.\n",
    "- Collaborative filtering refers to a family of methods for predicting ratings where instead of thinking about users and items in terms of a feature space, we are only interested in the existing user-item ratings themselves.\n",
    "- In this case, our dataset is a ratings matrix whose columns correspond to items, and whose rows correspond to users. This will be the general form of the data we analyse for collaborative filtering. The method relies on previous user-item ratings (or feedback).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cold-start problem\n",
    "- Collaborative filtering is susceptible to the Cold Start problem.\n",
    "- What happens if we don’t have any (or enough) reviews?\n",
    "- Until users rate several items, we don’t know anything about their preferences.\n",
    "- We can get around this by enhancing our recommendations using implicit feedback, which may include things like item browsing behaviour, search patterns, purchase history, etc. Or by using a hybrid model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jaccard Similarity:\n",
    "- Defines similarity between two sets of objects.\n",
    "<img src=\"img/jacard-similarity.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measuring error\n",
    "<img src=\"img/measuring-error.png\" align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explicit vs Implicit Data\n",
    "- Explicit data is when you ask the user to rate something, e.g. 1-5 star rating for a movie.\n",
    "- Implicit data is when you observe a users behaviour and record."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithms for Recommendations\n",
    "- Alternating Least Squares (ALS) \n",
    "- Stochastic Gradient Descent (SGD) \n",
    "- Singular Value Decomposition (SVD) \n",
    "- Factorization Machine (FM) \n",
    "- Collaborative Less is More Filtering (CLiMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Surprise\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import evaluate, print_perf\n",
    "from surprise import Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reader = Reader(line_format='user item rating timestamp', sep='\\t')\n",
    "\n",
    "data = Dataset.load_from_file(file_path = '../data/u.data', reader=reader)\n",
    "data.split(n_folds=3)\n",
    "\n",
    "algo = SVD()\n",
    "perf = evaluate(algo, data, measures=['RMSE', 'MAE'])\n",
    "print_perf(perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 3. Make individual recommendations\n",
    "uid = str(196)  # raw user id (as in the ratings file). They are **strings**!\n",
    "iid = str(302)  # raw item id (as in the ratings file). They are **strings**!\n",
    "\n",
    "# get a prediction for specific users and items.\n",
    "pred = algo.predict(uid, iid, r_ui=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Other recommendation algorithms:\n",
    "#random_pred.NormalPredictor    Algorithm predicting a random rating based on the distribution of the training set, which is assumed to be normal.\n",
    "#baseline_only.BaselineOnly    Algorithm predicting the baseline estimate for given user and item.\n",
    "#knns.KNNBasic    A basic collaborative filtering algorithm.\n",
    "#knns.KNNWithMeans    A basic collaborative filtering algorithm, taking into account the mean ratings of each user.\n",
    "#knns.KNNBaseline    A basic collaborative filtering algorithm taking into account a baseline rating.\n",
    "#matrix_factorization.SVD    The famous SVD algorithm, as popularized by Simon Funk during the Netflix Prize.\n",
    "#matrix_factorization.SVDpp    The SVD++ algorithm, an extension of SVD taking into account implicit ratings.\n",
    "#matrix_factorization.NMF    A collaborative filtering algorithm based on Non-negative Matrix Factorization.\n",
    "#slope_one.SlopeOne    A simple yet accurate collaborative filtering algorithm.\n",
    "#co_clustering.CoClustering    A collaborative filtering algorithm based on co-clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 5 Lesson 2\n",
    "## Databases + SQL in Python\n",
    "10 - 22 June 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Databases\n",
    "- Databases are computer systems that manage storage and querying of data. Databases provide a way to organise data along with efficient methods to retrieve specific information.\n",
    "- Typically, retrieval is performed using a query language, a mini programming syntax with a few basic operators for data transformation, the most common of which is SQL.\n",
    "- Databases are the standard solution for data storage and are much more robust than text, CSV or json files. Most analyses involve pulling data to and from a resource and in most settings, that means using a database.\n",
    "- Databases can come in many flavours, designed to serve for different use cases.\n",
    "- Databases are ‘modelled’ to suit their intended purpose. \n",
    "\n",
    "#### Relational databases and schema\n",
    "- A relational database is a database based tabular data and links between data entities or concepts.\n",
    "- A relational database is organised into tables. Each table should correspond to one entity or concept.\n",
    "- A table is made up rows and columns, similar to a Pandas dataframe or Excel spreadsheet.\n",
    "- A table also has a schema which is a set of rules for what goes in each table. These specify what columns are contained in the table and what type those columns are (text, integers, floats, etc.).\n",
    "\n",
    "#### Primary and foreign keys\n",
    "- Each table typically has a primary key column. This column is a unique value per row and serves as the identifier for the row.\n",
    "- A table can have many foreign keys as well. A foreign key is a column that contains values to link the table to the other tables.\n",
    "\n",
    "#### Transactions\n",
    "- A unit of work performed against a database is called a transaction. This term generally represents any change in database.\n",
    "- ACID is a set of properties that guarantee that database transactions are processed reliably.\n",
    " - Atomicity \"all or nothing\": if one part of the transaction fails, the entire transaction fails, and the database state is left unchanged.\n",
    " - Consistency ensures that any transaction will bring the database from one valid state to another.\n",
    " - Isolation ensures that the concurrent execution of transactions results in a system state that would be obtained if transactions were executed serially, i.e., one after the other.\n",
    " - Durability ensures that once a transaction has been committed, it will remain so, even in the event of power loss, crashes, or errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The sqlite3 package\n",
    "- The command line utility can be useful for basic SQL tasks, but since we're using python for the rest of code it will often be easier to access sqlite directly from within python. We can use the python sqlite3 package for just this purpose.\n",
    "- Open a connection to an SQLite database file. As before, if the file does not already exist it will automatically be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "sqlite_db = 'test_db.sqlite'\n",
    "conn = sqlite3.connect(sqlite_db) \n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The syntax to create a table is similar to the console, only now we use the execute method of the cursor object c that we just created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c.execute('CREATE TABLE houses (field1 INTEGER PRIMARY KEY, sqft INTEGER, bdrms INTEGER, age INTEGER, price INTEGER);')\n",
    "\n",
    "# Save (commit) the changes\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the database saved the table should now be viewable using SQLite Manager.\n",
    "\n",
    "#### Adding data\n",
    "\n",
    "Since we're back in python, we can now use regular programming techniques in conjunction with the sqlite connection.  In particular, the cursor's `execute()` method supports value substitutionusing the `?` character, which makes adding multiple records a bit easier.  See the [docs](https://docs.python.org/2.7/library/sqlite3.html) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_sale = (None, 4000, 5, 22, 619000)\n",
    "c.execute('INSERT INTO houses VALUES (?,?,?,?,?)',last_sale)\n",
    "\n",
    "# Remember to commit the changes\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Notice that in this syntax we use the python None value, rather than NULL, to trigger SQLite to auto-increment the Primary Key.\n",
    "- There is a related cursor method executemany() which takes an array of tuples and loops through them, substituting one tuple at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recent_sales = [\n",
    "  (None, 2390, 4, 34, 319000),\n",
    "  (None, 1870, 3, 14, 289000),\n",
    "  (None, 1505, 3, 90, 269000),\n",
    "]\n",
    "\n",
    "c.executemany('INSERT INTO houses VALUES (?, ?, ?, ?, ?)', recent_sales)\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c.execute('select * from houses').fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding data from a csv file\n",
    "- Next let's load our housing.csv data into an array, and then INSERT those records into the database. In this example we'll use the numpy genfromtxt function to read the file and parse the contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "\n",
    "# import into nparray of ints, then convert to list of lists\n",
    "data = genfromtxt('../data/housing-data.csv', dtype='i8', delimiter=',', skip_header=1).tolist()\n",
    "\n",
    "# append a None value to beginning of each sub-list\n",
    "for d in data:\n",
    "    d.insert(0, None)\n",
    "\n",
    "for d in data:\n",
    "    c.execute('INSERT INTO houses VALUES (?, ?, ?, ?, ?)', d)\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remember that all elements in a numpy array must be the same data type, so if we want to 'add a None' to each row, we need to work around this. Lists can contain mixed types, so that is one approach.\n",
    "- Still, in this case the value we're adding is the same for all records, so we could have simply used a 'None' in the INSERT statement directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deleting data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# similar syntax as before\n",
    "results = c.execute(\"SELECT * FROM houses WHERE bdrms = 4\")\n",
    "\n",
    "# here results is a cursor object - use fetchall() to extract a list\n",
    "results.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas connector\n",
    "\n",
    "- While databases provide many analytical capabilities, often it's useful to pull the data back into Python for more flexible programming. Large, fixed operations would be more efficient in a database, but Pandas allows for interactive processing.\n",
    "- For example, if you want to aggregate nightly log-ins or sales to present a report or dashboard, this operation is likely not changing and operating on a large dataset. This can run very efficiently in a database rather than by connecting to it with Python.\n",
    "- However, if we want to investigate login or sales data further and ask more interactive questions, then Python would be more practical.\n",
    "- Pandas can connect to most relational databases. In this demonstration, we will create and connect to a SQLite database.\n",
    "- SQLite creates portable SQL databases saved in a single file. These databases are stored in a very efficient manner and allow fast querying, making them ideal for small databases or databases that need to be moved across machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.io import sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing data into a database\n",
    "\n",
    "Data in Pandas can be loaded into a relational database. For the most part, Pandas can use column information to infer the schema for the table it creates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('../data/housing-data.csv', low_memory=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is moved to the database through the to_sql command, similar to the to_csv command.\n",
    "to_sql takes as arguments:\n",
    "- `name`, the table name to create\n",
    "- `con`, a connection to a database\n",
    "- `index`, whether to input the index column\n",
    "- `schema`, if we want to write a custom schema for the new table\n",
    "- `if_exists`, what to do if the table already exists. We can overwrite it, add to it, or fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_sql('houses_pandas',\n",
    "            con=conn,\n",
    "            if_exists='replace',\n",
    "            index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c.execute('select bdrms, avg(price) from houses_pandas group by bdrms').fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"guided-practice\"></a>\n",
    "\n",
    "\n",
    "### SQL Syntax \n",
    "\n",
    "\n",
    "###### Select\n",
    "Every query should start with `SELECT`.  `SELECT` is followed by the names of the columns in the output.\n",
    "\n",
    "`SELECT` is always paired with `FROM`, and `FROM` identifies the table to retrieve data from.\n",
    "\n",
    "```sql\n",
    "SELECT\n",
    "<columns>\n",
    "FROM\n",
    "<table>\n",
    "```\n",
    "\n",
    "`SELECT *` denotes returns *all* of the columns.\n",
    "\n",
    "Housing Data example:\n",
    "```sql\n",
    "SELECT\n",
    "sqft, bdrms\n",
    "FROM houses_pandas;\n",
    "```\n",
    "\n",
    "**Check:** Write a query that returns the `sqft`, `bdrms` and `price`.\n",
    ">\n",
    "```sql\n",
    "SELECT\n",
    "sqft, bdrms, price\n",
    "FROM houses_pandas;\n",
    "```\n",
    "\n",
    "##### Where\n",
    "\n",
    "`WHERE` is used to filter table to a specific criteria and follows the `FROM` clause.\n",
    "\n",
    "```sql\n",
    "SELECT\n",
    "<columns>\n",
    "FROM\n",
    "<table>\n",
    "WHERE\n",
    "<condition>\n",
    "```\n",
    "Example:\n",
    "```sql\n",
    "SELECT\n",
    "sqft, bdrms, age, price\n",
    "FROM houses_pandas\n",
    "WHERE bdrms = 2 and price < 250000;\n",
    "```\n",
    "\n",
    "The condition is some filter applied to the rows, where rows that match the condition will be in the output.\n",
    "\n",
    "**Check:** Write a query that returns the `sqft`, `bdrms`, `age` for when houses older than 60 years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aggregations\n",
    "\n",
    "Aggregations (or aggregate functions) are functions where the values of multiple rows are grouped together as input on certain criteria to form a single value of more significant meaning or measurement such as a set, a bag or a list.\n",
    "\n",
    "Examples of aggregate funtions:\n",
    "\n",
    "- Average (i.e., arithmetic mean)\n",
    "- Count\n",
    "- Maximum\n",
    "- Minimum\n",
    "- Median\n",
    "- Mode\n",
    "- Sum\n",
    "\n",
    "In SQL they are performed in a `SELECT` statement as follows.\n",
    "\n",
    "```sql\n",
    "SELECT COUNT(price)\n",
    "FROM houses_pandas;\n",
    "```\n",
    "\n",
    "```sql\n",
    "SELECT AVG(sqft), MIN(price), MAX(price)\n",
    "FROM houses_pandas\n",
    "WHERE bdrms = 2;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Joins\n",
    "\n",
    "Below is a link to a handy reference for SQL joins. In this chart joins are represented in terms of sets and venn diagrams. \n",
    "https://www.codeproject.com/Articles/33052/Visual-Representation-of-SQL-Joins\n",
    "\n",
    "Alternatively, remember the merge functionality of pandas.\n",
    "https://github.com/pandas-dev/pandas/blob/master/doc/cheatsheet/Pandas_Cheat_Sheet.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('../data/enron.db') \n",
    "c = conn.cursor()\n",
    "c.execute(\"SELECT name FROM sqlite_master WHERE type='table';\").fetchall()\n",
    "fields = c.execute(\"SELECT sql from sqlite_master WHERE type='table' and name='MessageBase';\").fetchall()\n",
    "print (''.join(fields[0]))\n",
    "fields = c.execute(\"SELECT sql from sqlite_master WHERE type='table' and name='RecipientBase';\").fetchall()\n",
    "print (''.join(fields[0]))\n",
    "fields = c.execute(\"SELECT sql from sqlite_master WHERE type='table' and name='EmployeeBase';\").fetchall()\n",
    "print (''.join(fields[0]))\n",
    "\n",
    "results = c.execute(\"SELECT * FROM EmployeeBase LIMIT 5;\").fetchall()\n",
    "for row in results:\n",
    "    print (row)\n",
    "\n",
    "import pandas as pd\n",
    "employees = pd.read_sql(\"SELECT * FROM EmployeeBase;\", conn)\n",
    "recipients = pd.read_sql(\"SELECT * FROM RecipientBase;\", conn)\n",
    "messages = pd.read_sql(\"SELECT * FROM MessageBase;\", conn)\n",
    "\n",
    "employees.describe()\n",
    "\n",
    "#representing data\n",
    "import scipy.special\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.plotting import figure, output_notebook, show\n",
    "p1 = figure(title=\"Distribution of Recipients\",tools=\"save\")\n",
    "hist, edges = np.histogram(recipients.rno, density=False, bins=10)\n",
    "x = np.arange(0,57)\n",
    "p1.quad(top=hist, bottom=0, left=edges[:10], right=edges[1:], fill_color=\"#008080\")\n",
    "p1.legend.location = \"center_right\"\n",
    "p1.xaxis.axis_label = 'No of Recipients'\n",
    "p1.yaxis.axis_label = 'Messages'\n",
    "output_notebook()\n",
    "show(p1)\n",
    "\n",
    "#Pandas merge\n",
    "rm = pd.merge(recipients,messages,on=\"mid\")\n",
    "rme = pd.merge(rm,employees,left_on=\"from_eid\",right_on=\"eid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional resources\n",
    "- [sqlite3 home](http://www.sqlite.org)  \n",
    "- [SQLite - Python tutorial](http://sebastianraschka.com/Articles/2014_sqlite_in_python_tutorial.html)  \n",
    "- [SQL zoo](http://www.sqlzoo.net)  Great for learning syntax"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
