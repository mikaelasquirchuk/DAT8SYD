{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Week 3 - Logistic Regression\n",
    "\n",
    "## EXERCISE: Predicting Survival on the Titanic\n",
    "\n",
    "The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n",
    "\n",
    "One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Survived      Pclass         Age       SibSp       Parch        Fare\n",
       "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TASK 1: read the data from titanic.csv into a DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "titanic = pd.read_csv('../../data/titanic.csv', index_col='PassengerId')\n",
    "\n",
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TASK 2: define Pclass/Parch as the features and Survived as the response\n",
    "feature_cols = ['Pclass', 'Parch']\n",
    "X = titanic[feature_cols]\n",
    "y = titanic.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TASK 3: split the data into training and testing sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x115f7c9c8>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TASK 4: fit a logistic regression model and examine the coefficients\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "zip(feature_cols, logreg.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.668161434978\n"
     ]
    }
   ],
   "source": [
    "# TASK 5: make predictions on testing set and calculate accuracy\n",
    "y_pred_class = logreg.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.686098654709\n"
     ]
    }
   ],
   "source": [
    "# TASK 6: add Age as a feature and calculate testing accuracy\n",
    "titanic.Age.fillna(titanic.Age.mean(), inplace=True)\n",
    "feature_cols = ['Pclass', 'Parch', 'Age']\n",
    "X = titanic[feature_cols]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "logreg.fit(X_train, y_train)\n",
    "zip(feature_cols, logreg.coef_[0])\n",
    "y_pred_class = logreg.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[112  16]\n",
      " [ 54  41]]\n"
     ]
    }
   ],
   "source": [
    "# TASK 7 : Confusion Matrix\n",
    "prds = logreg.predict(X)\n",
    "print(metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x116af7208>]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMn1UAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116845cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TASK 8: Generate the ROC Curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_class)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67264573991\n"
     ]
    }
   ],
   "source": [
    "# TASK 9: What variables should we include in the model to improve it?\n",
    "# There are no other functioning variables - all of the lower the accuracy.\n",
    "titanic.Age.fillna(titanic.Age.mean(), inplace=True)\n",
    "titanic.Fare.fillna(titanic.Fare.mean(), inplace=True)\n",
    "titanic.SibSp.fillna(titanic.SibSp.mean(), inplace=True)\n",
    "feature_cols = ['Pclass', 'Age','Parch', 'SibSp','Fare']\n",
    "X = titanic[feature_cols]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "logreg.fit(X_train, y_train)\n",
    "zip(feature_cols, logreg.coef_[0])\n",
    "y_pred_class = logreg.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.663677130045\n"
     ]
    }
   ],
   "source": [
    "# Task 10: Try a different classification algorithm like Naive Bayes or Nearest Neighbours\n",
    "#Gaussian Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred_class = gnb.fit(X_train, y_train).predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.654708520179\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "y_pred_class = knn.fit(X_train, y_train).predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Looks like Logistic Regression using 'Pclass' and 'Parch' and 'Age' is the most accurate \n",
    "# predictor of death on the Titanic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
