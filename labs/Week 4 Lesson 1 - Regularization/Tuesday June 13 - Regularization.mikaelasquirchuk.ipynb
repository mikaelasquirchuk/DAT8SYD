{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab - Regularization\n",
    "\n",
    "## Week 4 Tuesday 11th June\n",
    "\n",
    "### TASK: Regularized regression\n",
    "### FUNCTIONS: Ridge, RidgeCV, Lasso, LassoCV\n",
    "### DOCUMENTATION: http://scikit-learn.org/stable/modules/linear_model.html\n",
    "### DATA: Crime (n=319 non-null, p=122, type=regression)\n",
    "### DATA DICTIONARY: http://archive.ics.uci.edu/ml/datasets/Communities+and+Crime\n",
    "\n",
    "This data set contains data on violent crimes within a community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "########## Prepare data ##########\n",
    "# read in data, remove categorical features, remove rows with missing values\n",
    "import pandas as pd\n",
    "crime = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/communities/communities.data', header=None, na_values=['?'])\n",
    "crime = crime.iloc[:, 5:]\n",
    "crime.dropna(inplace=True)\n",
    "crime.head()\n",
    "\n",
    "# define X and y\n",
    "X = crime.iloc[:, :-1]\n",
    "y = crime.iloc[:, -1]\n",
    "\n",
    "# split into train/test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(319, 122)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many columns are in X?\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -3.66188167e+00,   6.98124465e-01,  -2.61955467e-01,\n",
       "        -2.85270027e-01,  -1.64740837e-01,   2.46972333e-01,\n",
       "        -1.09290051e+00,  -5.96857796e-01,   1.11200239e+00,\n",
       "        -7.21968931e-01,   4.27346598e+00,  -2.28040268e-01,\n",
       "         8.04875769e-01,  -2.57934732e-01,  -2.63458023e-01,\n",
       "        -1.04616958e+00,   6.07784197e-01,   7.73552561e-01,\n",
       "         5.96468029e-02,   6.90215922e-01,   2.16759430e-02,\n",
       "        -4.87802949e-01,  -5.18858404e-01,   1.39478815e-01,\n",
       "        -1.24417942e-01,   3.15003821e-01,  -1.52633736e-01,\n",
       "        -9.65003927e-01,   1.17142163e+00,  -3.08546690e-02,\n",
       "        -9.29085548e-01,   1.24654586e-01,   1.98104506e-01,\n",
       "         7.30804821e-01,  -1.77337294e-01,   8.32927588e-02,\n",
       "         3.46045601e-01,   5.01837338e-01,   1.57062958e+00,\n",
       "        -4.13478807e-01,   1.39350802e+00,  -3.49428114e+00,\n",
       "         7.09577818e-01,  -8.32141352e-01,  -1.39984927e+00,\n",
       "         1.02482840e+00,   2.13855006e-01,  -6.18937325e-01,\n",
       "         5.28954490e-01,   7.98294890e-02,   5.93688560e-02,\n",
       "        -1.68582667e-01,   7.31264051e-01,  -1.39635208e+00,\n",
       "         2.38507704e-01,   5.50621439e-01,  -5.61447867e-01,\n",
       "         6.18989764e-01,   2.55517024e+00,  -3.71769599e+00,\n",
       "         7.09191935e-01,   3.82041439e-01,   8.23752836e-01,\n",
       "        -1.67703547e+00,  -1.73150450e+00,   9.90120171e-01,\n",
       "        -5.72745697e-01,  -1.45877295e+00,   8.68032144e-01,\n",
       "         5.15959984e-01,   3.14453207e-02,   2.01869791e-01,\n",
       "         9.65291940e-02,   2.13034099e+00,  -6.95374423e-02,\n",
       "         4.62477023e-02,  -1.10565955e-02,  -1.34313780e-02,\n",
       "        -1.04515494e-01,  -8.76985171e-01,   4.26781907e-01,\n",
       "        -1.85405795e-01,  -8.16215517e-01,  -2.86596076e-01,\n",
       "        -1.56110708e-01,   1.76468580e+00,  -5.70163730e-01,\n",
       "        -7.54066704e-02,  -1.74212697e-01,  -8.89747220e-02,\n",
       "         2.26336403e-01,   1.38030073e+00,  -3.37304744e-01,\n",
       "        -2.57856611e-02,   8.91299188e-02,   3.49876793e-01,\n",
       "        -1.22428557e+00,  -3.67941205e+01,  -6.95699750e-01,\n",
       "         2.95269279e-01,  -1.48590316e-03,   2.34206416e-01,\n",
       "        -7.09533984e-03,   3.67152957e+01,  -8.90665109e-02,\n",
       "         3.79550678e-02,   3.19375782e-01,   4.60708905e-01,\n",
       "         1.41090069e-01,  -6.67017320e-01,  -2.59035245e-01,\n",
       "        -4.60600755e-04,  -1.51868232e-02,   7.54768410e-02,\n",
       "        -2.36105498e-03,  -1.50328233e-01,   1.85575558e-01,\n",
       "         6.31979224e-01,  -1.50253625e-01,   1.87638817e-02,\n",
       "        -3.38095851e-02,  -4.46104032e-01])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########## Linear Regression Model Without Regularization ##########\n",
    "# linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "lm.coef_\n",
    "# What are these numbers?\n",
    "# The coefficients of a linear regression model fit to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (no regularization) = 0.233813676495\n"
     ]
    }
   ],
   "source": [
    "# make predictions and evaluate\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "preds = lm.predict(X_test)\n",
    "print('RMSE (no regularization) =', np.sqrt(metrics.mean_squared_error(y_test, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (Ridge reg.) = 0.164279068049\n"
     ]
    }
   ],
   "source": [
    "########## Ridge Regression Model ##########\n",
    "# ridge regression (alpha must be positive, larger means more regularization)\n",
    "from sklearn.linear_model import Ridge\n",
    "rreg = Ridge(alpha=0.1, normalize=True)\n",
    "rreg.fit(X_train, y_train)\n",
    "rreg.coef_\n",
    "preds = rreg.predict(X_test)\n",
    "print('RMSE (Ridge reg.) =', np.sqrt(metrics.mean_squared_error(y_test, preds)))\n",
    "# Is this model better? Why?\n",
    "# Yes, this model is a better result. It is removing those coefficients / columns that don't play a part in predicting the value of X.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Alpha Value:  1.0\n",
      "RMSE (Ridge CV reg.) = 0.163129782343\n"
     ]
    }
   ],
   "source": [
    "# use RidgeCV to select best alpha\n",
    "from sklearn.linear_model import RidgeCV\n",
    "alpha_range = 10.**np.arange(-2, 3)\n",
    "rregcv = RidgeCV(normalize=True, scoring='neg_mean_squared_error', alphas=alpha_range)\n",
    "rregcv.fit(X_train, y_train)\n",
    "\n",
    "# Print the optimal value of Alpha for Ridge Regression\n",
    "print('Optimal Alpha Value: ', rregcv.alpha_)\n",
    "\n",
    "# Print the RMSE for the ridge regression model\n",
    "preds = rregcv.predict(X_test)\n",
    "print ('RMSE (Ridge CV reg.) =', np.sqrt(metrics.mean_squared_error(y_test, preds)))\n",
    "# What is the range of alpha values we are searching over?\n",
    "# We are searching from 0.01 (10^-2) and 1000 (10^3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (Lasso reg.) = 0.198165225429\n"
     ]
    }
   ],
   "source": [
    "########## Lasso Regression Model ##########\n",
    "# lasso (alpha must be positive, larger means more regularization)\n",
    "from sklearn.linear_model import Lasso\n",
    "las = Lasso(alpha=0.01, normalize=True)\n",
    "las.fit(X_train, y_train)\n",
    "las.coef_\n",
    "preds = las.predict(X_test)\n",
    "print('RMSE (Lasso reg.) =', np.sqrt(metrics.mean_squared_error(y_test, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (Lasso reg.) = 0.164502413721\n"
     ]
    }
   ],
   "source": [
    "# try a smaller alpha\n",
    "las = Lasso(alpha=0.0001, normalize=True)\n",
    "las.fit(X_train, y_train)\n",
    "las.coef_\n",
    "preds = las.predict(X_test)\n",
    "print('RMSE (Lasso reg.) =', np.sqrt(metrics.mean_squared_error(y_test, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Alpha Value:  0.001\n",
      "RMSE (Lasso CV reg.) = 0.160039024044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# use LassoCV to select best alpha (tries 100 alphas by default)\n",
    "from sklearn.linear_model import LassoCV\n",
    "alpha_range = 10.**np.arange(-10, 10)\n",
    "lascv = LassoCV(normalize=True, alphas=alpha_range)\n",
    "lascv.fit(X_train, y_train)\n",
    "print('Optimal Alpha Value: ',lascv.alpha_)\n",
    "lascv.coef_\n",
    "preds = lascv.predict(X_test)\n",
    "print('RMSE (Lasso CV reg.) =', np.sqrt(metrics.mean_squared_error(y_test, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Carry out Elastic net regularised regression\n",
    "\n",
    "### Lookup [Elastic Net](http://scikit-learn.org/stable/modules/linear_model.html#elastic-net) and complete the following.\n",
    "\n",
    "\n",
    "\n",
    "1. What is elastic net?\n",
    " * Elastic net is another a linear regression model trained with L1 and L2 prior as regularizer. This combination allows for learning a sparse model where few of the weights are non-zero like Lasso, while still maintaining the regularization properties of Ridge. We control the convex combination of L1 and L2 using the l1_ratio parameter.\n",
    " * Elastic-net is useful when there are multiple features which are correlated with one another. Lasso is likely to pick one of these at random, while elastic-net is likely to pick both.\n",
    " * A practical advantage of trading-off between Lasso and Ridge is it allows Elastic-Net to inherit some of Ridge’s stability under rotation.\n",
    "\n",
    "2. How does it work?\n",
    "* Elastic net combines Ridge Regression and Lasso regularisation.\n",
    "\n",
    "3. Run elastic net on the above dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (ENET reg.) 0.242253664949\n",
      "-----\n",
      "Optimal Alpha Value:  0.001\n",
      "RMSE (ENET CV reg.) 0.163708913832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Setup the elastic net model\n",
    "from sklearn.linear_model import ElasticNet\n",
    "enet = ElasticNet(alpha=0.1, l1_ratio=0.7)\n",
    "enet.fit(X_train, y_train)\n",
    "enet.coef_\n",
    "preds=enet.predict(X_test)\n",
    "\n",
    "print('RMSE (ENET reg.)', np.sqrt(metrics.mean_squared_error(y_test, preds)))\n",
    "print('-----')\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "enetCV = ElasticNetCV(normalize=True, alphas=alpha_range)\n",
    "enetCV.fit(X_train, y_train)\n",
    "print('Optimal Alpha Value: ',enetCV.alpha_)\n",
    "enetCV.coef_\n",
    "preds = enetCV.predict(X_test)\n",
    "print('RMSE (ENET CV reg.)', np.sqrt(metrics.mean_squared_error(y_test, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Task 2: Carry out Regularised Regression\n",
    "\n",
    "1. Run all three forms of regularised regression on the Boston Housing DataSet\n",
    "2. What do the coefficients mean?\n",
    "3. What would you advise someone living in Boston to try and raise the value of their home?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_boston\n",
    "  \n",
    "boston = load_boston()\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(boston[\"data\"])\n",
    "Y = boston[\"target\"]\n",
    "names = boston[\"feature_names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso CV model:  -3.729 * LSTAT + 2.824 * RM + -2.423 * DIS + -1.923 * PTRATIO + -1.576 * NOX + 1.192 * RAD + -0.845 * TAX + 0.767 * B + 0.708 * ZN + 0.658 * CHAS + -0.625 * CRIM + -0.0 * INDUS + -0.0 * AGE\n",
      "Optimal Alpha Value:  0.1\n",
      "RMSE (Lasso CV reg.) = 4.72740953777\n",
      "Ridge CV model:  -3.685 * LSTAT + -2.974 * DIS + 2.71 * RM + 2.338 * RAD + -2.023 * PTRATIO + -1.928 * NOX + -1.78 * TAX + 1.011 * ZN + -0.882 * CRIM + 0.854 * B + 0.697 * CHAS + 0.038 * INDUS + -0.008 * AGE\n",
      "Optimal Alpha Value:  0.01\n",
      "RMSE (Ridge CV reg.) = 4.68188565691\n",
      "ElasticNet model:  1.277 * RM + -1.186 * LSTAT + -0.772 * PTRATIO + -0.438 * INDUS + -0.413 * TAX + -0.396 * CRIM + 0.389 * B + 0.356 * CHAS + -0.352 * NOX + 0.326 * ZN + -0.261 * AGE + -0.203 * RAD + -0.046 * DIS\n",
      "Optimal Alpha Value:  0.01\n",
      "RMSE (Enet CV reg.) = 6.39988772499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:3: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  app.launch_new_instance()\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:3: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "#A helper method for pretty-printing linear models\n",
    "def pretty_print_linear(coefs, names = None, sort = False):\n",
    "    if names == None:\n",
    "        names = [\"X%s\" % x for x in range(len(coefs))]\n",
    "    lst = zip(coefs, names)\n",
    "    if sort:\n",
    "        lst = sorted(lst,  key = lambda x:-np.abs(x[0]))\n",
    "    return \" + \".join(\"%s * %s\" % (round(coef, 3), name)\n",
    "                                   for coef, name in lst)\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "lascv = LassoCV(alphas=alpha_range)\n",
    "alpha_range = 10.**np.arange(-10, 10)\n",
    "lascv.fit(X,Y)\n",
    "lascv.coef_\n",
    "preds=lascv.predict(X)\n",
    "print(\"Lasso CV model: \", pretty_print_linear(lascv.coef_, names, sort = True))\n",
    "print('Optimal Alpha Value: ',lascv.alpha_)\n",
    "print('RMSE (Lasso CV reg.) =', np.sqrt(metrics.mean_squared_error(Y, preds)))\n",
    "\n",
    "\n",
    "from sklearn.linear_model import RidgeCV\n",
    "alpha_range = 10.**np.arange(-10, 10)\n",
    "rregcv = RidgeCV(normalize=True, scoring='neg_mean_squared_error', alphas=alpha_range)\n",
    "rregcv.fit(X,Y)\n",
    "rregcv.coef_\n",
    "preds=rregcv.predict(X)\n",
    "print(\"Ridge CV model: \", pretty_print_linear(rregcv.coef_, names, sort = True))\n",
    "print('Optimal Alpha Value: ',rregcv.alpha_)\n",
    "print('RMSE (Ridge CV reg.) =', np.sqrt(metrics.mean_squared_error(Y, preds)))\n",
    "\n",
    "\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "enetCV = ElasticNetCV(normalize=True, alphas=alpha_range)\n",
    "enetCV.fit(X,Y)\n",
    "enetCV.coef_\n",
    "preds=enetCV.predict(X)\n",
    "print(\"ElasticNet model: \", pretty_print_linear(enetCV.coef_, names, sort = True))\n",
    "print('Optimal Alpha Value: ',enetCV.alpha_)\n",
    "print('RMSE (Enet CV reg.) =', np.sqrt(metrics.mean_squared_error(Y, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "#### What do the coefficients mean?\n",
    "The coefficients mean how much weight is given to each feature in order to determine the model. \n",
    "Ridge CV is the most effective model with the data. \n",
    "Therefore the percentage of lower class has a higher weight than the distance from employment.\n",
    "\n",
    "#### What would you advise someone living in Boston to try and raise the value of their home?\n",
    "Kill all the lower status people in their neighbourhood; move their house closer to the employment centres and add a room."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
